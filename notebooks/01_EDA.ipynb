{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27051e4f-36f8-412a-9e38-b83f85db6c92",
   "metadata": {},
   "source": [
    "# Lab 2 – Exploratory Data Analysis (EDA) and Cleaning\n",
    "**Author:** Anam Ayyub  \n",
    "**Dataset:** Derm7pt (meta.csv)  \n",
    "**Goal:** Explore metadata, clean features, prepare for baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ceb244-ec7e-4b76-a2a1-3534e1c6a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd3b1f-faa4-4688-86d7-ae78caf79532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASET_PATH = r\"C:\\Users\\anama\\Documents\\Group_8\\Dataset\\DERM7PT\"\n",
    "META_FILE = os.path.join(DATASET_PATH, \"meta\", \"meta.csv\")\n",
    "CLEAN_FILE = os.path.join(DATASET_PATH, \"meta\", \"metadata_cleaned.csv\")\n",
    "\n",
    "# Sanity checks\n",
    "assert os.path.exists(DATASET_PATH), f\"Dataset path not found: {DATASET_PATH}\"\n",
    "assert os.path.exists(META_FILE), f\"Metadata file not found: {META_FILE}\"\n",
    "\n",
    "print(\"Paths confirmed.\")\n",
    "print(\"Dataset path:\", DATASET_PATH)\n",
    "print(\"Meta file:\", META_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b7acba-a8b2-4c84-8d22-bedbc47302a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(META_FILE)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f533151-85e3-4bd2-82f1-4f45319bdcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column overview and basic checks\n",
    "cols = list(df.columns)\n",
    "print(\"Columns:\", cols)\n",
    "\n",
    "# Expected core columns\n",
    "expected_present = [\n",
    "    \"case_num\", \"diagnosis\", \"seven_point_score\", \"pigment_network\", \"streaks\",\n",
    "    \"pigmentation\", \"regression_structures\", \"dots_and_globules\", \"blue_whitish_veil\",\n",
    "    \"vascular_structures\", \"level_of_diagnostic_difficulty\", \"elevation\", \"location\",\n",
    "    \"sex\", \"management\", \"clinic\", \"derm\"\n",
    "]\n",
    "missing_expected = [c for c in expected_present if c not in df.columns]\n",
    "print(\"Missing expected columns (if any):\", missing_expected)\n",
    "\n",
    "\n",
    "for c in [\"case_id\", \"notes\"]:\n",
    "    if c in df.columns:\n",
    "        non_null = df[c].notna().sum()\n",
    "        print(f\"{c}: non-null count = {non_null} of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c50b04-d0d7-4619-997f-83bf1da394c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.countplot(x=\"diagnosis\", data=df, order=df[\"diagnosis\"].value_counts().index)\n",
    "plt.title(\"Diagnosis (class) distribution\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Diagnosis counts:\")\n",
    "display(df[\"diagnosis\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b808b28-81a3-41e3-b5dc-4d36263029ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values overview\n",
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "print(\"Missing values per column:\")\n",
    "display(missing)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x=missing.index, y=missing.values, color=\"steelblue\")\n",
    "plt.title(\"Missing values per column\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2298d62-820b-44c5-a5cc-d89ad1a44224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric feature overview\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "if \"seven_point_score\" in df.columns:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df[\"seven_point_score\"], bins=10, kde=True)\n",
    "    plt.title(\"Seven Point Score distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Quick correlation heatmap among numeric cols\n",
    "# Target encode all categorical columns for correlation\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols = [c for c in categorical_cols if c != \"diagnosis\"]\n",
    "\n",
    "df[\"target_binary\"] = df[\"diagnosis\"].str.contains(\"melanoma\").astype(int)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    means = df.groupby(col)[\"target_binary\"].mean()\n",
    "    df[col + \"_te\"] = df[col].map(means)\n",
    "\n",
    "# Combine all numeric + encoded columns\n",
    "encoded_cols = [c + \"_te\" for c in categorical_cols]\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "all_numeric = numeric_cols + encoded_cols\n",
    "\n",
    "# Compute full correlation matrix\n",
    "full_corr = df[all_numeric].corr()\n",
    "\n",
    "# Show top correlations with seven_point_score\n",
    "top_corr = full_corr[\"seven_point_score\"].drop(\"seven_point_score\").sort_values(ascending=False)\n",
    "print(\"Top correlations with seven_point_score:\")\n",
    "display(top_corr.head(5))\n",
    "\n",
    "# Optional: plot heatmap of top 5 correlations\n",
    "top_features = top_corr.head(5).index.tolist() + [\"seven_point_score\"]\n",
    "sns.heatmap(df[top_features].corr(), annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "plt.title(\"Top Correlations with Seven Point Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2424a0a-d449-4203-8f02-d03fb25d9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key categorical distributions (sex, location, clinic, derm, management, diagnostic difficulty)\n",
    "cat_to_plot = [\n",
    "    \"sex\", \"location\", \"clinic\", \"derm\", \"management\", \"level_of_diagnostic_difficulty\",\n",
    "    \"pigment_network\", \"streaks\", \"pigmentation\", \"regression_structures\",\n",
    "    \"dots_and_globules\", \"blue_whitish_veil\", \"vascular_structures\", \"elevation\"\n",
    "]\n",
    "for c in cat_to_plot:\n",
    "    if c in df.columns:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        order = df[c].value_counts().index\n",
    "        sns.countplot(x=c, data=df, order=order)\n",
    "        plt.title(f\"{c} distribution\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892f985-f2e5-4a91-bef2-472c49fe8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unusable/sparse columns\n",
    "# Rationale: near-empty, non-predictive for baselines; documented in notebook text.\n",
    "drop_cols = [c for c in [\"case_id\", \"notes\"] if c in df.columns]\n",
    "df_clean = df.drop(columns=drop_cols)\n",
    "print(\"Dropped columns:\", drop_cols)\n",
    "print(\"Clean shape:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e11a82-98e6-4ab0-b780-ffae7f70c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and Target Preparation\n",
    "\n",
    "# Step 1: Drop sparse/unusable columns\n",
    "drop_cols = [c for c in [\"case_id\", \"notes\"] if c in df.columns]\n",
    "df_clean = df.drop(columns=drop_cols)\n",
    "print(\"Dropped columns:\", drop_cols)\n",
    "print(\"Shape after drop:\", df_clean.shape)\n",
    "\n",
    "# Step 2: Define binary and multiclass targets\n",
    "melanoma_labels = [\n",
    "    \"melanoma\",\n",
    "    \"melanoma (less than 0.76 mm)\",\n",
    "    \"melanoma (in situ)\",\n",
    "    \"melanoma (0.76 to 1.5 mm)\",\n",
    "    \"melanoma (more than 1.5 mm)\",\n",
    "    \"melanoma metastasis\"\n",
    "]\n",
    "\n",
    "# Binary target: 1 = melanoma, 0 = benign/other\n",
    "y_binary = df_clean[\"diagnosis\"].apply(lambda x: 1 if x in melanoma_labels else 0)\n",
    "print(\"Binary target distribution:\\n\", y_binary.value_counts())\n",
    "\n",
    "# Multiclass target: one-hot encode diagnosis\n",
    "y_multiclass = pd.get_dummies(df_clean[\"diagnosis\"])\n",
    "print(\"Multiclass target shape:\", y_multiclass.shape)\n",
    "\n",
    "# Step 3: Encode categorical features (exclude diagnosis)\n",
    "categorical_cols = df_clean.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_to_encode = [c for c in categorical_cols if c != \"diagnosis\"]\n",
    "\n",
    "X = pd.get_dummies(\n",
    "    df_clean.drop(columns=[\"diagnosis\"]),\n",
    "    columns=categorical_to_encode,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Binary target shape:\", y_binary.shape)\n",
    "print(\"Multiclass target shape:\", y_multiclass.shape)\n",
    "\n",
    "# Step 4: Scale numeric features (exclude identifiers like case_num)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "scale_cols = [c for c in numeric_cols if c != \"case_num\"]\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Columns to scale:\", scale_cols)\n",
    "\n",
    "if scale_cols:\n",
    "    scaler = StandardScaler()\n",
    "    X[scale_cols] = scaler.fit_transform(X[scale_cols])\n",
    "\n",
    "# Step 5: Save outputs\n",
    "X.to_csv(os.path.join(DATASET_PATH, \"meta\", \"features.csv\"), index=False)\n",
    "y_binary.to_csv(os.path.join(DATASET_PATH, \"meta\", \"target_binary.csv\"), index=False)\n",
    "y_multiclass.to_csv(os.path.join(DATASET_PATH, \"meta\", \"target_multiclass.csv\"), index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - features.csv\")\n",
    "print(\" - target_binary.csv\")\n",
    "print(\" - target_multiclass.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426277d-f124-46c4-9adf-f237d2754282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric features (excluding identifiers like case_num)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_cols_post = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "# Exclude case_num from scaling (acts like an ID/order)\n",
    "scale_cols = [c for c in numeric_cols_post if c != \"case_num\"]\n",
    "\n",
    "print(\"Numeric columns after encoding:\", numeric_cols_post)\n",
    "print(\"Columns to scale:\", scale_cols)\n",
    "\n",
    "if scale_cols:\n",
    "    scaler = StandardScaler()\n",
    "    X[scale_cols] = scaler.fit_transform(X[scale_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7818702-9cc9-4fd6-a1f5-fc0d337969f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned metadata\n",
    "X.to_csv(CLEAN_FILE, index=False)\n",
    "print(f\"Cleaned metadata saved to: {CLEAN_FILE}\")\n",
    "print(\"Final columns:\", list(X.columns))\n",
    "print(\"Final shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044cfda-3e5e-4280-8583-c78c48371692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of cleaned outputs\n",
    "\n",
    "X = pd.read_csv(os.path.join(DATASET_PATH, \"meta\", \"features.csv\"))\n",
    "y_binary = pd.read_csv(os.path.join(DATASET_PATH, \"meta\", \"target_binary.csv\"))\n",
    "y_multiclass = pd.read_csv(os.path.join(DATASET_PATH, \"meta\", \"target_multiclass.csv\"))\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"Features:\", X.shape)\n",
    "print(\"Binary target:\", y_binary.shape)\n",
    "print(\"Multiclass target:\", y_multiclass.shape)\n",
    "\n",
    "# Quick sanity check: all should have the same number of rows\n",
    "assert len(X) == len(y_binary) == len(y_multiclass), \"Row mismatch detected!\"\n",
    "print(\"All aligned correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56828f88-79af-4719-bab7-f707801c948f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df[\"diagnosis\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ee054-a04c-4e3f-bc04-c292a142ea2a",
   "metadata": {},
   "source": [
    "# Lab 2 – EDA and Cleaning (Summary & Executive Notes)\n",
    "\n",
    "---\n",
    "\n",
    "### Step‑by‑Step Summary\n",
    "\n",
    "1. **Setup and Imports**  \n",
    "   - Loaded pandas, numpy, seaborn, matplotlib.  \n",
    "   - Defined dataset paths for reproducibility.  \n",
    "\n",
    "2. **Data Loading**  \n",
    "   - Read `meta.csv` into `df`.  \n",
    "   - Inspected shape, dtypes, and non‑null counts.  \n",
    "   - *Why:* Confirm schema and data quality.  \n",
    "\n",
    "3. **Exploratory Data Analysis (EDA)**  \n",
    "   - Checked class balance (`diagnosis`).  \n",
    "   - Visualized distributions of numeric and categorical features.  \n",
    "   - Plotted missing values.  \n",
    "   - Correlation heatmap among numeric features.  \n",
    "   - *Why:* Understand imbalance, feature coverage, and guide cleaning.  \n",
    "\n",
    "4. **Cleaning Decisions**  \n",
    "   - **Dropped Columns:**  \n",
    "     - `case_id` → ~97% missing, identifier only.  \n",
    "     - `notes` → ~99% missing, free‑text, not usable.  \n",
    "   - Preserved `case_num` but excluded from scaling.  \n",
    "   - *Why:* Avoid noise and target leakage.  \n",
    "\n",
    "5. **Target Preparation**  \n",
    "   - Kept raw `diagnosis`.  \n",
    "   - Created `y_binary` (melanoma=1, others=0).  \n",
    "   - Created `y_multiclass` (one‑hot encoded diagnosis).  \n",
    "   - *Why:* Supports both binary and multiclass experiments.  \n",
    "\n",
    "6. **Feature Engineering**  \n",
    "   - One‑hot encoded categorical features (excluding `diagnosis`).  \n",
    "   - Scaled numeric features (`seven_point_score`, etc.), excluding `case_num`.  \n",
    "   - *Why:* Ensure features are numeric and standardized for models.  \n",
    "\n",
    "7. **Saving Outputs**  \n",
    "   - Saved:  \n",
    "     - `features.csv` – cleaned, encoded, scaled feature matrix.  \n",
    "     - `target_binary.csv` – binary labels (melanoma vs. benign/other).  \n",
    "     - `target_multiclass.csv` – multiclass labels (20 categories).  \n",
    "     - `metadata_cleaned.csv` – cleaned metadata table.  \n",
    "   - Verified alignment: all outputs have consistent row counts.  \n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary – Lab 2 (EDA & Cleaning)\n",
    "\n",
    "- **Objective:** Prepare Derm7pt metadata for modeling by exploring, cleaning, and transforming features into a machine‑learning‑ready format.  \n",
    "\n",
    "- **Key Steps:**  \n",
    "  - Inspected dataset structure, distributions, and missing values.  \n",
    "  - Dropped sparse/non‑predictive columns (`case_id`, `notes`).  \n",
    "  - One‑hot encoded categorical features; standardized numeric features.  \n",
    "  - Created two target sets:  \n",
    "    - **Binary target:** grouped all melanoma subtypes into class **1 (melanoma)**, and all other diagnoses into class **0 (benign/other)**.  \n",
    "    - **Multiclass target:** one‑hot encoded all 20 diagnosis categories.  \n",
    "\n",
    "- **Outputs:**  \n",
    "  - `features.csv` – cleaned, encoded, scaled feature matrix.  \n",
    "  - `target_binary.csv` – binary labels.  \n",
    "  - `target_multiclass.csv` – multiclass labels.  \n",
    "  - `metadata_cleaned.csv` – cleaned metadata table.  \n",
    "\n",
    "- **Why it matters:** Establishes a reproducible, clean foundation for Lab 3 baselines (logistic regression, decision trees, etc.) and future multimodal fusion with images.  \n",
    "\n",
    "---\n",
    "\n",
    "**Status:** Lab 2 is complete. Next step: use `X` + `y_binary` for binary baselines, and `X` + `y_multiclass` for multiclass experiments in Lab 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce71ab7-19bd-46e8-9be6-1709d43c322f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Findings – Lab 2 (EDA)\n",
    "\n",
    "- **Class imbalance:** Melanoma cases form a minority compared to benign/other diagnoses, confirming the need for careful handling of imbalance in downstream models.  \n",
    "- **Missingness concentrated:** `case_id` (~97% missing) and `notes` (~99% missing) were essentially unusable, while most other features had good coverage.  \n",
    "- **Numeric features:** `seven_point_score` showed a skewed distribution, with most cases clustered at lower scores. Correlations among numeric features were weak, suggesting limited redundancy.  \n",
    "- **Categorical distributions:** Features like `sex`, `location`, and `management` were unevenly distributed, with some categories dominating (e.g., certain body locations more frequent).  \n",
    "- **Data integrity:** After cleaning and encoding, all feature and target files aligned perfectly in row counts, ensuring reproducibility for Lab 3.  \n",
    "\n",
    "---\n",
    "\n",
    "**conclusion:** The dataset is imbalanced but structurally sound after cleaning. With binary and multiclass targets prepared, the project is ready to progress into baseline modeling (Lab 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7bba9-67d6-4c27-8bde-92ddc7e29b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
